{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/malojan/nlp_nli/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: datasets==2.6 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (14.0.2)\n",
      "Requirement already satisfied: dill<0.3.6 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (0.3.5.1)\n",
      "Requirement already satisfied: pandas in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (0.70.13)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets==2.6) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (0.20.1)\n",
      "Requirement already satisfied: packaging in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from datasets==2.6) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from aiohttp->datasets==2.6) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from aiohttp->datasets==2.6) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from aiohttp->datasets==2.6) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from aiohttp->datasets==2.6) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from aiohttp->datasets==2.6) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from aiohttp->datasets==2.6) (4.0.3)\n",
      "Requirement already satisfied: filelock in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.6) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.6) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.6) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from pandas->datasets==2.6) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from pandas->datasets==2.6) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from pandas->datasets==2.6) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.6) (1.16.0)\n",
      "Requirement already satisfied: optuna==3.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: alembic in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (1.13.1)\n",
      "Requirement already satisfied: cliff in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (4.4.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (0.10.0)\n",
      "Requirement already satisfied: colorlog in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (6.8.0)\n",
      "Requirement already satisfied: numpy in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (23.2)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (1.8.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (2.0.25)\n",
      "Requirement already satisfied: tqdm in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (4.9.0)\n",
      "Requirement already satisfied: PyYAML in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from optuna==3.0) (6.0.1)\n",
      "Requirement already satisfied: Mako in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from alembic->optuna==3.0) (1.3.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from cliff->optuna==3.0) (3.9.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from cliff->optuna==3.0) (0.5.2)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from cliff->optuna==3.0) (2.4.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from cliff->optuna==3.0) (7.0.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from cliff->optuna==3.0) (5.1.0)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from cmd2>=1.0.0->cliff->optuna==3.0) (23.2.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from cmd2>=1.0.0->cliff->optuna==3.0) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from cmd2>=1.0.0->cliff->optuna==3.0) (0.2.12)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from importlib-metadata>=4.4->cliff->optuna==3.0) (3.17.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from stevedore>=2.0.1->cliff->optuna==3.0) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (from Mako->alembic->optuna==3.0) (2.1.3)\n",
      "Requirement already satisfied: sentencepiece in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (0.1.99)\n",
      "Requirement already satisfied: protobuf in /Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages (4.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets==2.6\n",
    "!pip install optuna==3.0\n",
    "!pip install sentencepiece\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load general packages\n",
    "# some more specialised packages are loaded in each sub section\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "SEED_GLOBAL = 42\n",
    "np.random.seed(SEED_GLOBAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training and test sets after sampling:  1000  (train)  8789  (test).\n"
     ]
    }
   ],
   "source": [
    "# import twitter data\n",
    "\n",
    "df = pd.read_csv('twitter_sentiment_data.csv')\n",
    "\n",
    "# Recode - 1 into 3\n",
    "df['sentiment'] = df['sentiment'].replace(-1,3)\n",
    "\n",
    "# Rename sentiment into label\n",
    "\n",
    "df = df.rename(columns={'sentiment': 'label'})\n",
    "\n",
    "# Rename message to text\n",
    "\n",
    "df = df.rename(columns={'message': 'text'})\n",
    "# Create a label_text column \n",
    "\n",
    "df['label_text'] = df['label'].replace({0: 'Climate: neutral', 1: 'Climate: believe', 2: 'Climate: news', 3: 'Climate: deny'})\n",
    "\n",
    "# Split into train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=SEED_GLOBAL)\n",
    "\n",
    "sample_size = 1000\n",
    "df_train = df_train.sample(n=min(sample_size, len(df_train)), random_state=SEED_GLOBAL).copy(deep=True)\n",
    "print(\"Length of training and test sets after sampling: \", len(df_train), \" (train) \", len(df_test), \" (test).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of each class in train set: \n",
      "label_text\n",
      "Climate: believe    525\n",
      "Climate: news       222\n",
      "Climate: neutral    163\n",
      "Climate: deny        90\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of each class in train set: \")\n",
    "print(df_train['label_text'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating hypothesis\n",
    "\n",
    "hypothesis_label_dic = {\n",
    "    \"Climate: news\" : \"(News): the tweet links to factual news about climate change\",\n",
    "    \"Climate: believe\": \"(Pro): the tweet supports the belief of man-made climate change\",\n",
    "    \"Climate: deny\": \"The tweet does not believe in man-made climate change\",\n",
    "    \"Climate: neutral\": \"Neutral: the tweet neither supports nor refutes the belief of man-made climate change\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df_train before formatting step: 1000.\n",
      "After adding not_entailment training examples, the training data was augmented to 1950 texts.\n",
      "Max augmentation could be: len(df_train) * 2 = 2000. It can also be lower, if there are more entail examples than not-entail for a majority class.\n"
     ]
    }
   ],
   "source": [
    "## function for reformatting the train set\n",
    "def format_nli_trainset(df_train=None, hypo_label_dic=None, random_seed=42):\n",
    "  print(f\"Length of df_train before formatting step: {len(df_train)}.\")\n",
    "  length_original_data_train = len(df_train)\n",
    "\n",
    "  df_train_lst = []\n",
    "  for label_text, hypothesis in hypo_label_dic.items():\n",
    "    ## entailment\n",
    "    df_train_step = df_train[df_train.label_text == label_text].copy(deep=True)\n",
    "    df_train_step[\"hypothesis\"] = [hypothesis] * len(df_train_step)\n",
    "    df_train_step[\"label\"] = [0] * len(df_train_step)\n",
    "    ## not_entailment\n",
    "    df_train_step_not_entail = df_train[df_train.label_text != label_text].copy(deep=True)\n",
    "    df_train_step_not_entail = df_train_step_not_entail.sample(n=min(len(df_train_step), len(df_train_step_not_entail)), random_state=random_seed)\n",
    "    df_train_step_not_entail[\"hypothesis\"] = [hypothesis] * len(df_train_step_not_entail)\n",
    "    df_train_step_not_entail[\"label\"] = [1] * len(df_train_step_not_entail)\n",
    "    # append\n",
    "    df_train_lst.append(pd.concat([df_train_step, df_train_step_not_entail]))\n",
    "  df_train = pd.concat(df_train_lst)\n",
    "  \n",
    "  # shuffle\n",
    "  df_train = df_train.sample(frac=1, random_state=random_seed)\n",
    "  df_train[\"label\"] = df_train.label.apply(int)\n",
    "  df_train[\"label_nli_explicit\"] = [\"True\" if label == 0 else \"Not-True\" for label in df_train[\"label\"]]  # adding this just to simplify readibility\n",
    "\n",
    "  print(f\"After adding not_entailment training examples, the training data was augmented to {len(df_train)} texts.\")\n",
    "  print(f\"Max augmentation could be: len(df_train) * 2 = {length_original_data_train*2}. It can also be lower, if there are more entail examples than not-entail for a majority class.\")\n",
    "\n",
    "  return df_train.copy(deep=True)\n",
    "\n",
    "\n",
    "df_train_formatted = format_nli_trainset(df_train=df_train, hypo_label_dic=hypothesis_label_dic, random_seed=SEED_GLOBAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>label_text</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label_nli_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15840</th>\n",
       "      <td>1</td>\n",
       "      <td>The head of the EPA just made another dangerou...</td>\n",
       "      <td>841739967491645440</td>\n",
       "      <td>Climate: believe</td>\n",
       "      <td>The tweet does not believe in man-made climate...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37108</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @NASA_EO: New NOAA study refutes the notion...</td>\n",
       "      <td>608945384510078976</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>(Pro): the tweet supports the belief of man-ma...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @savetheredwoods: Ecologist Todd Dawson des...</td>\n",
       "      <td>797553946197753856</td>\n",
       "      <td>Climate: neutral</td>\n",
       "      <td>(Pro): the tweet supports the belief of man-ma...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23947</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @BraddJaffy: Rex Tillerson in focus as NY A...</td>\n",
       "      <td>882986402681688064</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>(Pro): the tweet supports the belief of man-ma...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>1</td>\n",
       "      <td>Yet some say there is no global warming https:...</td>\n",
       "      <td>801990910955388930</td>\n",
       "      <td>Climate: believe</td>\n",
       "      <td>(News): the tweet links to factual news about ...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @EcoInternet3: Read President #Trump's exec...</td>\n",
       "      <td>846856160170926081</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>(Pro): the tweet supports the belief of man-ma...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25719</th>\n",
       "      <td>1</td>\n",
       "      <td>The most effective individual steps to tackle ...</td>\n",
       "      <td>901789438237388801</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>(Pro): the tweet supports the belief of man-ma...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @SenSanders: We have a president-elect who ...</td>\n",
       "      <td>798768783523360769</td>\n",
       "      <td>Climate: believe</td>\n",
       "      <td>(Pro): the tweet supports the belief of man-ma...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39551</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @MinnDad: @FredZeppelin12 Man made global w...</td>\n",
       "      <td>671487584091160576</td>\n",
       "      <td>Climate: deny</td>\n",
       "      <td>The tweet does not believe in man-made climate...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38045</th>\n",
       "      <td>1</td>\n",
       "      <td>Obama Uses Alaska Visit To Focus On Climate Ch...</td>\n",
       "      <td>638668400718422016</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>(Pro): the tweet supports the belief of man-ma...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1950 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "15840      1  The head of the EPA just made another dangerou...   \n",
       "37108      1  RT @NASA_EO: New NOAA study refutes the notion...   \n",
       "4359       1  RT @savetheredwoods: Ecologist Todd Dawson des...   \n",
       "23947      1  RT @BraddJaffy: Rex Tillerson in focus as NY A...   \n",
       "7701       1  Yet some say there is no global warming https:...   \n",
       "...      ...                                                ...   \n",
       "17769      1  RT @EcoInternet3: Read President #Trump's exec...   \n",
       "25719      1  The most effective individual steps to tackle ...   \n",
       "5913       0  RT @SenSanders: We have a president-elect who ...   \n",
       "39551      0  RT @MinnDad: @FredZeppelin12 Man made global w...   \n",
       "38045      1  Obama Uses Alaska Visit To Focus On Climate Ch...   \n",
       "\n",
       "                  tweetid        label_text  \\\n",
       "15840  841739967491645440  Climate: believe   \n",
       "37108  608945384510078976     Climate: news   \n",
       "4359   797553946197753856  Climate: neutral   \n",
       "23947  882986402681688064     Climate: news   \n",
       "7701   801990910955388930  Climate: believe   \n",
       "...                   ...               ...   \n",
       "17769  846856160170926081     Climate: news   \n",
       "25719  901789438237388801     Climate: news   \n",
       "5913   798768783523360769  Climate: believe   \n",
       "39551  671487584091160576     Climate: deny   \n",
       "38045  638668400718422016     Climate: news   \n",
       "\n",
       "                                              hypothesis label_nli_explicit  \n",
       "15840  The tweet does not believe in man-made climate...           Not-True  \n",
       "37108  (Pro): the tweet supports the belief of man-ma...           Not-True  \n",
       "4359   (Pro): the tweet supports the belief of man-ma...           Not-True  \n",
       "23947  (Pro): the tweet supports the belief of man-ma...           Not-True  \n",
       "7701   (News): the tweet links to factual news about ...           Not-True  \n",
       "...                                                  ...                ...  \n",
       "17769  (Pro): the tweet supports the belief of man-ma...           Not-True  \n",
       "25719  (Pro): the tweet supports the belief of man-ma...           Not-True  \n",
       "5913   (Pro): the tweet supports the belief of man-ma...               True  \n",
       "39551  The tweet does not believe in man-made climate...               True  \n",
       "38045  (Pro): the tweet supports the belief of man-ma...           Not-True  \n",
       "\n",
       "[1950 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hypotheses/classes:  4\n",
      "Original test set size: 8789\n",
      "Test set size for NLI classification: 35156\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>label_text</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label_nli_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34461</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @vincecable: Nice summary. Add climate chan...</td>\n",
       "      <td>955713180684177408</td>\n",
       "      <td>Climate: neutral</td>\n",
       "      <td>(News): the tweet links to factual news about ...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34461</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @vincecable: Nice summary. Add climate chan...</td>\n",
       "      <td>955713180684177408</td>\n",
       "      <td>Climate: neutral</td>\n",
       "      <td>(Pro): the tweet supports the belief of man-ma...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34461</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @vincecable: Nice summary. Add climate chan...</td>\n",
       "      <td>955713180684177408</td>\n",
       "      <td>Climate: neutral</td>\n",
       "      <td>The tweet does not believe in man-made climate...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34461</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @vincecable: Nice summary. Add climate chan...</td>\n",
       "      <td>955713180684177408</td>\n",
       "      <td>Climate: neutral</td>\n",
       "      <td>Neutral: the tweet neither supports nor refute...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20916</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @CNN: Former US President Obama will speak ...</td>\n",
       "      <td>861896636313817089</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>(News): the tweet links to factual news about ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5638</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @StephenSchlegel: she's thinking about how ...</td>\n",
       "      <td>798618059003035653</td>\n",
       "      <td>Climate: believe</td>\n",
       "      <td>Neutral: the tweet neither supports nor refute...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17989</th>\n",
       "      <td>0</td>\n",
       "      <td>Exxon to Trump: Don't ditch Paris climate chan...</td>\n",
       "      <td>847226330361937921</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>(News): the tweet links to factual news about ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17989</th>\n",
       "      <td>1</td>\n",
       "      <td>Exxon to Trump: Don't ditch Paris climate chan...</td>\n",
       "      <td>847226330361937921</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>(Pro): the tweet supports the belief of man-ma...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17989</th>\n",
       "      <td>1</td>\n",
       "      <td>Exxon to Trump: Don't ditch Paris climate chan...</td>\n",
       "      <td>847226330361937921</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>The tweet does not believe in man-made climate...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17989</th>\n",
       "      <td>1</td>\n",
       "      <td>Exxon to Trump: Don't ditch Paris climate chan...</td>\n",
       "      <td>847226330361937921</td>\n",
       "      <td>Climate: news</td>\n",
       "      <td>Neutral: the tweet neither supports nor refute...</td>\n",
       "      <td>Not-True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35156 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "34461     1  RT @vincecable: Nice summary. Add climate chan...   \n",
       "34461     1  RT @vincecable: Nice summary. Add climate chan...   \n",
       "34461     1  RT @vincecable: Nice summary. Add climate chan...   \n",
       "34461     0  RT @vincecable: Nice summary. Add climate chan...   \n",
       "20916     0  RT @CNN: Former US President Obama will speak ...   \n",
       "...     ...                                                ...   \n",
       "5638      1  RT @StephenSchlegel: she's thinking about how ...   \n",
       "17989     0  Exxon to Trump: Don't ditch Paris climate chan...   \n",
       "17989     1  Exxon to Trump: Don't ditch Paris climate chan...   \n",
       "17989     1  Exxon to Trump: Don't ditch Paris climate chan...   \n",
       "17989     1  Exxon to Trump: Don't ditch Paris climate chan...   \n",
       "\n",
       "                  tweetid        label_text  \\\n",
       "34461  955713180684177408  Climate: neutral   \n",
       "34461  955713180684177408  Climate: neutral   \n",
       "34461  955713180684177408  Climate: neutral   \n",
       "34461  955713180684177408  Climate: neutral   \n",
       "20916  861896636313817089     Climate: news   \n",
       "...                   ...               ...   \n",
       "5638   798618059003035653  Climate: believe   \n",
       "17989  847226330361937921     Climate: news   \n",
       "17989  847226330361937921     Climate: news   \n",
       "17989  847226330361937921     Climate: news   \n",
       "17989  847226330361937921     Climate: news   \n",
       "\n",
       "                                              hypothesis label_nli_explicit  \n",
       "34461  (News): the tweet links to factual news about ...           Not-True  \n",
       "34461  (Pro): the tweet supports the belief of man-ma...           Not-True  \n",
       "34461  The tweet does not believe in man-made climate...           Not-True  \n",
       "34461  Neutral: the tweet neither supports nor refute...               True  \n",
       "20916  (News): the tweet links to factual news about ...               True  \n",
       "...                                                  ...                ...  \n",
       "5638   Neutral: the tweet neither supports nor refute...           Not-True  \n",
       "17989  (News): the tweet links to factual news about ...               True  \n",
       "17989  (Pro): the tweet supports the belief of man-ma...           Not-True  \n",
       "17989  The tweet does not believe in man-made climate...           Not-True  \n",
       "17989  Neutral: the tweet neither supports nor refute...           Not-True  \n",
       "\n",
       "[35156 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## function for reformatting the test set\n",
    "def format_nli_testset(df_test=None, hypo_label_dic=None):\n",
    "  ## explode test dataset for N hypotheses\n",
    "  hypothesis_lst = [value for key, value in hypo_label_dic.items()]\n",
    "  print(\"Number of hypotheses/classes: \", len(hypothesis_lst))\n",
    "\n",
    "  # label lists with 0 at alphabetical position of their true hypo, 1 for not-true hypos\n",
    "  label_text_label_dic_explode = {}\n",
    "  for key, value in hypo_label_dic.items():\n",
    "    label_lst = [0 if value == hypo else 1 for hypo in hypothesis_lst]\n",
    "    label_text_label_dic_explode[key] = label_lst\n",
    "\n",
    "  df_test[\"label\"] = df_test.label_text.map(label_text_label_dic_explode)\n",
    "  df_test[\"hypothesis\"] = [hypothesis_lst] * len(df_test)\n",
    "  print(f\"Original test set size: {len(df_test)}\")\n",
    "  \n",
    "  # explode dataset to have K-1 additional rows with not_entail label and K-1 other hypotheses\n",
    "  # ! after exploding, cannot sample anymore, because distorts the order to true label values, which needs to be preserved for evaluation code\n",
    "  df_test = df_test.explode([\"hypothesis\", \"label\"])  # multi-column explode requires pd.__version__ >= '1.3.0'\n",
    "  print(f\"Test set size for NLI classification: {len(df_test)}\\n\")\n",
    "\n",
    "  df_test[\"label_nli_explicit\"] = [\"True\" if label == 0 else \"Not-True\" for label in df_test[\"label\"]]  # adding this just to simplify readibility\n",
    "\n",
    "  return df_test.copy(deep=True)\n",
    "\n",
    "\n",
    "df_test_formatted = format_nli_testset(df_test=df_test, hypo_label_dic=hypothesis_label_dic)\n",
    "df_test_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malo/anaconda3/envs/nli/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "## load the BERT-NLI model and its tokenizer\n",
    "# you can choose any of the NLI models here: https://huggingface.co/MoritzLaurer\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"  # English model: \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"; multilingual model: \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# If torch available, add cuda as device, if not add mps if available, if not add cpu\n",
    "\n",
    "# check if GPU or MPS is available, else use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "model.to(device);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas dataframes to Hugging Face dataset object to facilitate pre-processing\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.DatasetDict({\n",
    "    \"train\": datasets.Dataset.from_pandas(df_train_formatted),\n",
    "    \"test\": datasets.Dataset.from_pandas(df_test_formatted)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 18.17ba/s]\n",
      "100%|██████████| 36/36 [00:01<00:00, 23.94ba/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "def tokenize_nli_format(examples):\n",
    "  return tokenizer(examples[\"text\"], examples[\"hypothesis\"], truncation=True, max_length=512)  # max_length can be reduced to e.g. 256 to increase speed, but long texts will be cut off\n",
    "dataset[\"train\"] = dataset[\"train\"].map(tokenize_nli_format, batched=True)  \n",
    "dataset[\"test\"] = dataset[\"test\"].map(tokenize_nli_format, batched=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall structure of the pre-processed train and test sets:\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text', 'tweetid', 'label_text', 'hypothesis', 'label_nli_explicit', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1950\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text', 'tweetid', 'label_text', 'hypothesis', 'label_nli_explicit', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 35156\n",
      "    })\n",
      "})\n",
      "\n",
      "\n",
      "An example for a tokenized hypothesis-context pair:\n",
      "\n",
      "{'label': 1, 'text': 'The head of the EPA just made another dangerous comment about global warming https://t.co/Q1FahdFe3F', 'tweetid': 841739967491645440, 'label_text': 'Climate: believe', 'hypothesis': 'The tweet does not believe in man-made climate change', 'label_nli_explicit': 'Not-True', '__index_level_0__': 15840, 'input_ids': [1, 279, 761, 265, 262, 9388, 348, 412, 501, 3051, 1714, 314, 1307, 6965, 3597, 294, 320, 320, 297, 260, 1902, 320, 4090, 435, 31538, 31132, 23058, 508, 1490, 2, 279, 8522, 490, 298, 770, 267, 642, 271, 5029, 2424, 575, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(\"The overall structure of the pre-processed train and test sets:\\n\")\n",
    "print(dataset)\n",
    "\n",
    "print(\"\\n\\nAn example for a tokenized hypothesis-context pair:\\n\")\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging\n",
    "import torch\n",
    "# Set the directory to write the fine-tuned model and training logs to.\n",
    "# With google colab, this will create a temporary folder, which will be deleted once you disconnect. \n",
    "# You can connect to your personal google drive to save models and logs properly.\n",
    "training_directory = \"BERT-nli-demo\"\n",
    "\n",
    "# FP16 is a hyperparameter which can increase training speed and reduce memory consumption, but only on GPU and if batch-size > 8, see here: https://huggingface.co/transformers/performance.html?#fp16\n",
    "# FP16 does not work on CPU or for multilingual mDeBERTa models\n",
    "fp16_bool = True if torch.cuda.is_available() else False\n",
    "if \"mdeberta\" in model_name.lower(): fp16_bool = False  # multilingual mDeBERTa does not support FP16 yet: https://github.com/microsoft/DeBERTa/issues/77\n",
    "# in case of hyperparameter search end the end: FP16 has to be set to False. The integrated hyperparameter search with the Hugging Face Trainer can lead to errors otherwise. \n",
    "fp16_bool = False\n",
    "\n",
    "# Hugging Face tipps to increase training speed and decrease out-of-memory (OOM) issues: https://huggingface.co/transformers/performance.html?\n",
    "# Overview of all training arguments: https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=f'./results/{training_directory}',\n",
    "    logging_dir=f'./logs/{training_directory}',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,  # if you get an out-of-memory error, reduce this value to 8 or 4 and restart the runtime. Higher values increase training speed, but also increase memory requirements. Ideal values here are always a multiple of 8.\n",
    "    per_device_eval_batch_size=80,  # if you get an out-of-memory error, reduce this value, e.g. to 40 and restart the runtime\n",
    "    #gradient_accumulation_steps=4, # Can be used in case of memory problems to reduce effective batch size. accumulates gradients over X steps, only then backward/update. decreases memory usage, but also slightly speed. (!adapt/halve batch size accordingly)\n",
    "    num_train_epochs=3,  # this can be increased, but higher values increase training time. Good values for NLI are between 3 and 20.\n",
    "    warmup_ratio=0.25,  # a good normal default value is 0.06 for normal BERT-base models, but since we want to reuse prior NLI knowledge and avoid catastrophic forgetting, we set the value higher\n",
    "    weight_decay=0.1,\n",
    "    seed=SEED_GLOBAL,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=fp16_bool,  # Can speed up training and reduce memory consumption, but only makes sense at batch-size > 8. loads two copies of model weights, which creates overhead. https://huggingface.co/transformers/performance.html?#fp16\n",
    "    fp16_full_eval=fp16_bool,\n",
    "    evaluation_strategy=\"no\", # options: \"no\"/\"steps\"/\"epoch\"\n",
    "    #eval_steps=10_000,  # evaluate after n steps if evaluation_strategy!='steps'. defaults to logging_steps\n",
    "    save_strategy = \"no\",  # options: \"no\"/\"steps\"/\"epoch\"\n",
    "    #save_steps=10_000,              # Number of updates steps before two checkpoint saves.\n",
    "    #save_total_limit=10,             # If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in output_dir\n",
    "    #logging_strategy=\"steps\",\n",
    "    report_to=\"all\",  # \"all\"  # logging\n",
    "    #push_to_hub=False,\n",
    "    #push_to_hub_model_id=f\"{model_name}-finetuned-{task}\",\n",
    ")\n",
    "\n",
    "# helper function to clean memory and reduce risk of out-of-memory error\n",
    "import gc\n",
    "def clean_memory():\n",
    "  #del(model)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "  gc.collect()\n",
    "\n",
    "clean_memory()\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support, accuracy_score, classification_report\n",
    "\n",
    "def compute_metrics_nli_binary(eval_pred, label_text_alphabetical=None):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    ### reformat model output to enable calculation of standard metrics\n",
    "    # split in chunks with predictions for each hypothesis for one unique premise\n",
    "    def chunks(lst, n):  # Yield successive n-sized chunks from lst. https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "        for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n]\n",
    "\n",
    "    # for each chunk/premise, select the most likely hypothesis\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    prediction_chunks_lst = list(chunks(predictions, len(set(label_text_alphabetical)) ))\n",
    "    hypo_position_highest_prob = []\n",
    "    for i, chunk in enumerate(prediction_chunks_lst):\n",
    "        hypo_position_highest_prob.append(np.argmax(np.array(chunk)[:, 0]))  # only accesses the first column of the array, i.e. the entailment/true prediction logit of all hypos and takes the highest one\n",
    "\n",
    "    label_chunks_lst = list(chunks(labels, len(set(label_text_alphabetical)) ))\n",
    "    label_position_gold = []\n",
    "    for chunk in label_chunks_lst:\n",
    "        label_position_gold.append(np.argmin(chunk))  # argmin to detect the position of the 0 among the 1s\n",
    "\n",
    "    print(\"Highest probability prediction per premise: \", hypo_position_highest_prob)\n",
    "    print(\"Correct label per premise: \", label_position_gold)\n",
    "\n",
    "    ### calculate standard metrics\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(label_position_gold, hypo_position_highest_prob, average='macro')  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(label_position_gold, hypo_position_highest_prob, average='micro')  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    acc_balanced = balanced_accuracy_score(label_position_gold, hypo_position_highest_prob)\n",
    "    acc_not_balanced = accuracy_score(label_position_gold, hypo_position_highest_prob)\n",
    "    metrics = {'f1_macro': f1_macro,\n",
    "               'f1_micro': f1_micro,\n",
    "               'accuracy_balanced': acc_balanced,\n",
    "               'accuracy_not_b': acc_not_balanced,\n",
    "               #'precision_macro': precision_macro,\n",
    "               #'recall_macro': recall_macro,\n",
    "               #'precision_micro': precision_micro,\n",
    "               #'recall_micro': recall_micro,\n",
    "               #'label_gold_raw': label_position_gold,\n",
    "               #'label_predicted_raw': hypo_position_highest_prob\n",
    "               }\n",
    "    print(\"Aggregate metrics: \", {key: metrics[key] for key in metrics if key not in [\"label_gold_raw\", \"label_predicted_raw\"]} )  # print metrics but without label lists\n",
    "    print(\"Detailed metrics: \", classification_report(label_position_gold, hypo_position_highest_prob, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]), target_names=label_text_alphabetical, sample_weight=None, digits=2, output_dict=True,\n",
    "                                zero_division='warn'), \"\\n\")\n",
    "    return metrics\n",
    "\n",
    "# Create alphabetically ordered list of the original dataset classes/labels \n",
    "# This is necessary to be sure that the ordering of the test set labels and predictions is the same. Otherwise there is a risk that labels and predictions are in a different order and resulting metrics are wrong.\n",
    "label_text_alphabetical = np.sort(df_train.label_text.unique())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/366 [00:00<?, ?it/s]You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 14%|█▎        | 50/366 [02:01<17:06,  3.25s/it]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 4.11 GB, other allocations: 14.18 GB, max allowed: 18.13 GB). Tried to allocate 256 bytes on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/malo/Documents/interventions/nlp_nli/demo.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malo/Documents/interventions/nlp_nli/demo.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# training\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malo/Documents/interventions/nlp_nli/demo.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer( \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malo/Documents/interventions/nlp_nli/demo.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malo/Documents/interventions/nlp_nli/demo.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malo/Documents/interventions/nlp_nli/demo.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m eval_pred: compute_metrics_nli_binary(eval_pred, label_text_alphabetical\u001b[39m=\u001b[39mlabel_text_alphabetical)  \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malo/Documents/interventions/nlp_nli/demo.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/malo/Documents/interventions/nlp_nli/demo.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/nli/lib/python3.10/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1538\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1539\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1540\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1541\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1542\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/nli/lib/python3.10/site-packages/transformers/trainer.py:1854\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1853\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1854\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1856\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1857\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1859\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1860\u001b[0m ):\n\u001b[1;32m   1861\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/nli/lib/python3.10/site-packages/transformers/trainer.py:2746\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2743\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2744\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mbackward(loss)\n\u001b[0;32m-> 2746\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39;49mdetach() \u001b[39m/\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mgradient_accumulation_steps\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 4.11 GB, other allocations: 14.18 GB, max allowed: 18.13 GB). Tried to allocate 256 bytes on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "# training\n",
    "trainer = Trainer( \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=train_args,\n",
    "    train_dataset=dataset[\"train\"],  #.shard(index=1, num_shards=100),  # could shard data for faster testing https://huggingface.co/docs/datasets/processing.html#sharding-the-dataset-shard\n",
    "    eval_dataset=dataset[\"test\"],  #.shard(index=1, num_shards=100),  \n",
    "    compute_metrics=lambda eval_pred: compute_metrics_nli_binary(eval_pred, label_text_alphabetical=label_text_alphabetical)  \n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate the fine-tuned model on the held-out test set\n",
    "results = trainer.evaluate()## Evaluate the fine-tuned model on the held-out test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate the fine-tuned model on the held-out test set\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
