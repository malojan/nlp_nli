---
title: "Using Natural Language Inference for Text Classification"
author: "Malo Jan & Luis Sattelmayer"
format: revealjs
bibliography: references.bib
---

## Introduction

- Presentation of @laurer_less_2023, new ML engineer at HF. 
- NLI : zero-shot model : HF trend
- Method paper on using NLI for text classification

## Context

-   Imbalanced and scarce data

## Main contribution of the paper

-   Two main components of transfer learning : 
  - Language representations (Usually learned during pre-training with MLM) : eg. BERT
  - Task representations (Usually learned during fine-tuning)

- But BERT-base trained on MLM task not on a classification task and this layer usually deleted for fine tuning


- Other papers on few shot learning : Brown et al 2020, Schicke and Schutze 2021

## What is NLI ?

-   Text
-   Context sentence : premise
-   Hypothesis
-   Label : entailment, contradiction, neutral

## NLI as a classification task

- @yin2020universal, @wang2021entailment
- See Yin, Hay and Roth 2019 and refined Wang et al 2021
-   Classic Bert fine-tuning for text classification
    -   Transfer of the language knowledge
    -   Pre-trained model has no knowledge of the task nor the specific domain
-   BERT-NLI
    -   Transfer of the language & task knowledge
    -   NLI is a task that can be applied to any classification task
    -   Works well because data rich task

- Model : Deberta fine-tuned on 8 general purpose NLI datasets on more than 1 million examples of hypothesis context pairs

## Methods and design {.smaller}

-   Data : several manually annotated datasets in political science (CMP, CAP, CoronatNet...) of different sizes, domain, unit
-   8 classification tasks
-   Comparison of the following models at different ammount of training data [0,100,500,1000,2500,5000,1000] : 

| Model | SVM tf-idf | LR tf-idf | SVM-embeddings | LR-embeddings | Deberta-base | BERT-NLI |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
| knowledge transfer |No |No |Shallow |Shallow | Deep | Deep |
| task transfer |No |No |No |No |No | Deep  |

## 

![](results.png){width="90%" height="70%" fig-align="center"}

## Conclusion

BERT-LNI useful when : 

- Little training data
- Imbalanced data


-   BERT-NLI useful when little data and imbalanced
- Perform quite wellwith imbalanced data and so for many classes classification
  - BERT-NLI can predict class without having seen a single exemple (zero shot)
-   Less useful when large data, BERT fine-tuning similar or better
- After 2000 exemples, convergence of performance of BERT and BERT-NLI (perform well on minority class but less well on majority class)

If not : more advisable to use classical BERT
- Other limits : 
  - Perform less well with complex concepts ( traditional morality) than simpler (military positive) 
  - NLI english data rich task but not necessarily in other languages even if multilingual models are available

## Pros ans cons

- Important feature of NLI : label verbalization (similar as a prompt) : 
  - Pros : Task can be express in plain language
  - Cons : results depend on how the hypothesis is formulated (kind of ahyperparameter), same issues than In context learning
  
-   Pros over ChatGpt type of zero shot/few shot learning :
    -   Free/open source
-   Results might depend on how the hypothesis is formulated (kind of a prompt/hyperparameter)
-   Does this really solve the annotation issue ?

## Perspectives

-   Zero-shot NLI as initial sampling for active learning, find positive exemples of a rare class in the first sampling round
-   Cheaper than GPT-3 for zero-shot

## References

-   [Github repo](https://github.com/MoritzLaurer/less-annotating-with-bert-nli/tree/master)
